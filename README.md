# ðŸš€ FURIApp Connect - Plataforma de ConexÃ£o Inteligente para FÃ£s da FURIA

**AplicaÃ§Ã£o web que conecta fÃ£s da FURIA atravÃ©s de perfis personalizados e chatbot com IA local**, desenvolvida como soluÃ§Ã£o tÃ©cnica para o processo seletivo da FURIA Tech.

[![Deploy na Vercel](https://img.shields.io/badge/LIVE%20DEMO-%23000000.svg?style=for-the-badge&logo=vercel&logoColor=white)]((https://furiapp-connect.vercel.app/))
[![Stack: Next.js](https://img.shields.io/badge/Stack-Next.js-000000?style=for-the-badge&logo=nextdotjs)]()

## âœ¨ Destaques TÃ©cnicos
- **Chatbot com LLM local** via Ollama (sem dependÃªncia de APIs externas)
- **GeraÃ§Ã£o de perfis personalizados** baseada em preferÃªncias do usuÃ¡rio
- **Sistema de match** entre fÃ£s com perfis compatÃ­veis
- **Arquitetura modular** com TypeScript e Tailwind CSS

## ðŸ§  IA Contextualizada (Ollama Integration)
```mermaid
graph LR
    A[FormulÃ¡rio do FÃ£] --> B(Perfil Personalizado)
    B --> C[Chatbot IA]
    C --> D[Ollama Local]
    D --> E[Respostas Contextuais]
```
- **Modelos suportados:** Mistral, Llama2, ou outros via Ollama
- **Contexto dinÃ¢mico:** Utiliza dados do perfil para personalizar respostas
- **Privacidade:** Processamento 100% local

## ðŸ› ï¸ Tech Stack
| Camada          | Tecnologias                                                                 |
|-----------------|-----------------------------------------------------------------------------|
| **Frontend**    | Next.js, React, TypeScript, Tailwind CSS, Shadcn/ui                         |
| **IA**          | Ollama (mistral, llama2), LangChain (opcional)                              |
| **Hospedagem**  | Vercel                                                                      |
| **Ferramentas** | VS Code, Git, Ollama CLI                                                    |

## âš™ï¸ Como Executar Localmente

### PrÃ©-requisitos
- Node.js >= 18.x
- [Ollama instalado](https://ollama.com/download)

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/nathartigas/FURIApp_Connect.git

# 2. Instale dependÃªncias
npm install

# 3. Inicie o modelo de IA (terminal separado)
ollama run mistral  # ou seu modelo preferido

# 4. Execute a aplicaÃ§Ã£o
npm run dev
```
Acesse: http://localhost:3000

## ðŸ“‚ Estrutura de CÃ³digo
```bash
src/
â”œâ”€â”€ app/           # Rotas da aplicaÃ§Ã£o
â”œâ”€â”€ components/    # Componentes reutilizÃ¡veis
â”‚   â”œâ”€â”€ ui/        # Componentes do Shadcn/ui
â”‚   â”œâ”€â”€ chat/      # LÃ³gica do chatbot
â”‚   â””â”€â”€ profile/   # GeraÃ§Ã£o de perfis
â”œâ”€â”€ lib/           # UtilitÃ¡rios e integraÃ§Ã£o com Ollama
â”œâ”€â”€ types/         # Tipos TypeScript
â””â”€â”€ public/        # Assets estÃ¡ticos
```

## ðŸŽ¯ Funcionalidades Implementadas
| Funcionalidade       | Status | Dificuldade | ObservaÃ§Ãµes                     |
|----------------------|--------|-------------|---------------------------------|
| Landing Page         | âœ…     | â­â˜†â˜†â˜†â˜†      | Design responsivo               |
| FormulÃ¡rio do FÃ£     | âœ…     | â­â­â˜†â˜†â˜†     | ValidaÃ§Ã£o em tempo real         |
| GeraÃ§Ã£o de Perfil    | âœ…     | â­â­â­â˜†â˜†     | Algoritmo de matching           |
| Chat com IA Local    | âœ…     | â­â­â­â­â˜†     | IntegraÃ§Ã£o complexa com Ollama  |
| Sistema de Match     | âœ…     | â­â­â­â˜†â˜†     | ComparaÃ§Ã£o de perfis           |
| Deploy na Vercel     | âœ…     | â­â­â˜†â˜†â˜†     | ConfiguraÃ§Ã£o CI/CD              |

## ðŸ“Œ Desafios TÃ©cnicos Superados
1. **IntegraÃ§Ã£o Ollama-Frontend:** 
   - SoluÃ§Ã£o: ComunicaÃ§Ã£o via fetch API com endpoint local
   - Desafio: Gerenciamento de sessÃµes de chat

2. **PersonalizaÃ§Ã£o de Respostas:**
   - ImplementaÃ§Ã£o: InjeÃ§Ã£o de contexto no prompt do LLM
   ```typescript
   const prompt = `VocÃª Ã© um assistente da FURIA. O usuÃ¡rio Ã© fÃ£ do jogador ${userPlayer}. Responda: ${userInput}`
   ```

3. **OtimizaÃ§Ã£o de Performance:**
   - TÃ©cnicas: Cache de respostas, streaming de tokens

## âœï¸ Autora
**Nathalia Artigas**  
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=flat&logo=linkedin)](https://www.linkedin.com/in/nathalia-calazans-artigas-741b0b277/)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=flat&logo=github)](https://github.com/nathartigas)

> Projeto desenvolvido como parte do processo seletivo para a FURIA Tech - Maio/2025
